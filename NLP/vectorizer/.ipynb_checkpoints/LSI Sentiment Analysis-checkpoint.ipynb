{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import glob\n",
    "from nlp.vectorizer.dictionary_builder import build_dictionary, save\n",
    "from nlp.vectorizer.tfidf_vectorizer import build_TfIdfModel_from_list_of_texts, save_tfidf_model, convert_text_to_tfidf\n",
    "from nlp.vectorizer.lsi_vectorizer import save_lsi_model, convert_text_to_lsi, build_LsiTopicModel\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_document(filename):\n",
    "    s = []\n",
    "    flist = glob.glob(filename)\n",
    "    for fname in flist:\n",
    "        tfile = open(fname, \"r\", encoding=\"utf-8\", errors='ignore')\n",
    "        line = tfile.read()  # read the content of file and store in \"line\"\n",
    "        tfile.close()  # close the file\n",
    "        s.append(line)\n",
    "    return s\n",
    "\n",
    "def get_dictionary(documents, output) :\n",
    "    my_dict = build_dictionary(documents)\n",
    "    save(my_dict, output)\n",
    "    return my_dict\n",
    "\n",
    "def get_tfidf_model(documents, dictionary, output) :\n",
    "    tfidf_model = build_TfIdfModel_from_list_of_texts(documents, dictionary)\n",
    "    save_tfidf_model(tfidf_model, output)\n",
    "    return tfidf_model\n",
    "\n",
    "def get_lsi_model(documents, dictionary_filename, tfidf_output, numtopics, output) :\n",
    "    lsi_model = build_LsiTopicModel(documents, dictionary_filename, tfidf_output, numtopics)\n",
    "    save_lsi_model(output, lsi_model)\n",
    "    return lsi_model\n",
    "\n",
    "def sort_keywords(tfidf, reverse=True) :\n",
    "    #sorted by Idf value of each word\n",
    "    #idf value would return tuple (0,0.123231) => 1st element is the key in the dictionary, 2nd element is the idf value\n",
    "    #higher of idf value means higher word frequency\n",
    "    return sorted(tfidf, key=lambda item : item[1], reverse=reverse)\n",
    "\n",
    "def get_keywords(tfidf, dictionary) :\n",
    "    sorted_keywords = sort_keywords(tfidf)\n",
    "    keywords = map(lambda item: dictionary.get(item[0]), sorted_keywords)\n",
    "    #you have to convert it back to list if you want to return the values\n",
    "    return list(keywords)\n",
    "\n",
    "\n",
    "def labeling_sentiment(documents):\n",
    "    labels=[]\n",
    "    sizedocument=len(documents)\n",
    "    for i in range(sizedocument):\n",
    "        if (i % 2)==0:\n",
    "            labels.append(1.0)\n",
    "        else:\n",
    "            labels.append(-1.0)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def generate_lsi_vector(documents, lsi_model, dictionary, tfidf_model):\n",
    "    list_of_lsi_vector=[]\n",
    "    for d in documents:\n",
    "        lsi_vector=convert_text_to_lsi(d, dictionary, \n",
    "                                       tfidf_model, lsi_model)\n",
    "        list_of_lsi_vector.append(lsi_vector)\n",
    "    return list_of_lsi_vector\n",
    "\n",
    "\n",
    "def _get_lsi_values(item) :\n",
    "    return reduce((lambda acc, _item : acc + [_item[1]] ), item, list())\n",
    "\n",
    "def get_lsi_values(list_of_lsi_vector) :\n",
    "    return reduce((lambda lsi_values, item : lsi_values + [_get_lsi_values(item)] ), list_of_lsi_vector, list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-28 21:38:10,816 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-08-28 21:38:12,318 : INFO : built Dictionary(48736 unique tokens: ['ada', 'adalah', 'adanya', 'ade', 'agar']...) from 2969 documents (total 1428944 corpus positions)\n",
      "2018-08-28 21:38:12,341 : INFO : saving Dictionary object under dictionary/artikel_result.dict, separately None\n",
      "2018-08-28 21:38:12,363 : INFO : saved dictionary/artikel_result.dict\n",
      "2018-08-28 21:38:24,862 : INFO : collecting document frequencies\n",
      "2018-08-28 21:38:24,863 : INFO : PROGRESS: processing document #0\n",
      "2018-08-28 21:38:25,172 : INFO : calculating IDF weights for 2969 documents and 48735 features (693048 matrix non-zeros)\n",
      "2018-08-28 21:38:25,355 : INFO : saving TfidfModel object under tf_idf/artikel_result.tfidf, separately None\n",
      "2018-08-28 21:38:25,632 : INFO : saved tf_idf/artikel_result.tfidf\n",
      "2018-08-28 21:38:25,637 : INFO : loading Dictionary object from dictionary/artikel_result.dict\n",
      "2018-08-28 21:38:25,698 : INFO : loaded dictionary/artikel_result.dict\n",
      "2018-08-28 21:38:25,700 : INFO : loading TfidfModel object from tf_idf/artikel_result.tfidf\n",
      "2018-08-28 21:38:25,910 : INFO : loaded tf_idf/artikel_result.tfidf\n",
      "2018-08-28 21:38:45,806 : INFO : using serial LSI version on this node\n",
      "2018-08-28 21:38:45,807 : INFO : updating model with new documents\n",
      "2018-08-28 21:38:45,808 : INFO : preparing a new chunk of documents\n",
      "2018-08-28 21:38:46,067 : INFO : using 100 extra samples and 2 power iterations\n",
      "2018-08-28 21:38:46,069 : INFO : 1st phase: constructing (48736, 200) action matrix\n",
      "2018-08-28 21:38:46,291 : INFO : orthonormalizing (48736, 200) action matrix\n",
      "2018-08-28 21:38:53,422 : INFO : 2nd phase: running dense svd on (200, 2969) matrix\n",
      "2018-08-28 21:38:54,180 : INFO : computing the final decomposition\n",
      "2018-08-28 21:38:54,181 : INFO : keeping 100 factors (discarding 25.690% of energy spectrum)\n",
      "2018-08-28 21:38:54,366 : INFO : processed documents up to #2969\n",
      "2018-08-28 21:38:54,377 : INFO : topic #0(8.652): 0.186*\"anak\" + 0.158*\"anda\" + 0.108*\"jantung\" + 0.108*\"kanker\" + 0.102*\"darah\" + 0.100*\"bayi\" + 0.094*\"makanan\" + 0.093*\"ibu\" + 0.086*\"penyakit\" + 0.085*\"diabetes\"\n",
      "2018-08-28 21:38:54,380 : INFO : topic #1(4.426): 0.412*\"asi\" + 0.368*\"bayi\" + 0.273*\"anak\" + 0.263*\"ibu\" + -0.175*\"diabetes\" + -0.170*\"jantung\" + 0.131*\"menyusui\" + -0.128*\"gula\" + 0.117*\"formula\" + -0.117*\"darah\"\n",
      "2018-08-28 21:38:54,382 : INFO : topic #2(4.328): -0.371*\"kanker\" + 0.233*\"asi\" + -0.192*\"hepatitis\" + -0.184*\"hpv\" + 0.170*\"makanan\" + -0.164*\"serviks\" + 0.152*\"bayi\" + -0.139*\"vaksin\" + -0.135*\"virus\" + -0.130*\"hiv\"\n",
      "2018-08-28 21:38:54,385 : INFO : topic #3(4.136): 0.488*\"anak\" + -0.242*\"asi\" + -0.190*\"kanker\" + 0.171*\"tidur\" + -0.170*\"bayi\" + -0.137*\"ibu\" + -0.136*\"payudara\" + -0.133*\"vitamin\" + -0.117*\"kehamilan\" + -0.113*\"kulit\"\n",
      "2018-08-28 21:38:54,388 : INFO : topic #4(3.909): -0.533*\"kanker\" + -0.254*\"anak\" + 0.162*\"hepatitis\" + -0.151*\"serviks\" + -0.141*\"payudara\" + -0.126*\"hpv\" + 0.119*\"hiv\" + -0.107*\"makanan\" + 0.104*\"darah\" + 0.101*\"obat\"\n",
      "2018-08-28 21:38:54,419 : INFO : saving Projection object under lsi/artikel_result.lsi.projection, separately None\n",
      "2018-08-28 21:38:55,293 : INFO : saved lsi/artikel_result.lsi.projection\n",
      "2018-08-28 21:38:55,294 : INFO : saving LsiModel object under lsi/artikel_result.lsi, separately None\n",
      "2018-08-28 21:38:55,295 : INFO : not storing attribute projection\n",
      "2018-08-28 21:38:55,296 : INFO : not storing attribute dispatcher\n",
      "2018-08-28 21:38:55,329 : INFO : saved lsi/artikel_result.lsi\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filename = r'artikel/*.txt'\n",
    "    output_filedict = 'dictionary/artikel_result.dict'\n",
    "    output_tfidf = 'tf_idf/artikel_result.tfidf'\n",
    "    output_lsi = \"lsi/artikel_result.lsi\"\n",
    "    \n",
    "    documents = load_document(filename)\n",
    "    dictionary = get_dictionary(documents, output_filedict)\n",
    "\n",
    "    #get our tfidf_model\n",
    "    tfidf_model = get_tfidf_model(documents, dictionary, output_tfidf)\n",
    "    \n",
    "    #get lsi model\n",
    "    lsi_model = get_lsi_model(documents, output_filedict, output_tfidf, 100, output_lsi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    labels = labeling_sentiment(documents)\n",
    "    list_of_lsi_vector = generate_lsi_vector(documents, lsi_model, dictionary, tfidf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    list_of_lsi_values = get_lsi_values(list_of_lsi_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "[0.31340277881363526, -0.17873327104514491, 0.033885392202418284, 0.02494094846788862, 0.038820745905250385, 0.057400185094827756, -0.1968728278573526, -0.03946640700862913, 0.0018997393478939653, 0.02776916132028745, 0.11639261453729195, -0.06522015782509287, -0.05085329111053569, -0.05057011905627114, 0.047335557248805206, 0.0951693606228714, 0.04819085320671879, 0.10703211546705786, 0.11825671305262338, 0.013003571205236542, 0.09495010331522365, 0.026770076609212233, -0.0742270183795625, -0.060635498194013496, 0.05262728431197605, 0.014152093408801992, -0.02773222255492764, 0.020311912487043202, 0.052108167790078354, 0.058455715193515355, -0.010854336597747061, -0.0056022236078424196, -0.034836033984715645, -0.002615003650990818, 0.011243573304026266, -0.027873094262071664, -0.0008550456729464093, -0.05325387919458913, 0.017803316690094245, 0.021070512892197066, -0.04660218506036753, 0.03364441039339408, -0.0316825992358212, -0.03049905751876317, -0.05396238537683693, 0.00772188633910293, -0.009404868336268855, 0.033994134173500015, -0.04757006622723719, 0.05594596281408639, 0.14732498981499315, -0.08060444090410665, -0.04181224275598227, -0.03909455208104897, 0.045880907913215564, -0.014646752604548003, 0.05648997170783996, -0.007445941704556626, -0.022649102149341814, 0.05961883171926714, 3.0463537147669222e-05, 0.01857949292060213, 0.03246015044150174, 0.020751910388302812, 0.012892841324795262, 0.08683125945823716, -0.025834895559114567, -0.03100715439544099, 0.014700687367362308, 0.04364168124757803, 0.025424412745490163, -0.07145639406783434, 0.02468354695850712, -0.02946102086918046, 0.09681983703553404, -0.07013244324248971, -0.08363392505553957, 0.0027786320515400193, 0.058673297107098135, -0.032501446756465886, -0.020665814946724457, -0.014948565666737317, 0.03449648750452425, -0.017487083454646557, 0.022325439296826934, -0.03917132519860501, 0.06904106833402106, 0.00423331823318345, -0.0033485254849636775, -0.02520064350675541, 0.04336085361612049, -0.01540684544407375, 0.011533016098455758, -0.009320233130477798, -0.06698033438224735, 0.08551847623474489, -0.009360827736882484, -0.027171420873567022, -0.00880474493089416, 0.0788931826612643]\n",
      "1.0\n",
      "acc_train 0.972\n",
      "acc_test 0.5036119711042312\n"
     ]
    }
   ],
   "source": [
    "    x_train=list_of_lsi_values[:2000]\n",
    "    x_test=list_of_lsi_values[2000:]\n",
    "\n",
    "    y_train=labels[:2000]\n",
    "    y_test=labels[2000:]\n",
    "\n",
    "    print('===============================================')\n",
    "    print(x_train[0])\n",
    "    print(y_train[0])\n",
    "\n",
    "    rfmodel=RandomForestClassifier(criterion='gini')\n",
    "    rfmodel.fit(x_train,y_train)\n",
    "\n",
    "    pred_x_train=rfmodel.predict(x_train)\n",
    "    pred_x_test=rfmodel.predict(x_test)\n",
    "\n",
    "    acc_train=accuracy_score(y_train, pred_x_train)\n",
    "    acc_test=accuracy_score(y_test, pred_x_test)\n",
    "\n",
    "    print('acc_train', acc_train)\n",
    "    print('acc_test', acc_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
