{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from nlp.vectorizer.dictionary_builder import build_dictionary, save\n",
    "from nlp.vectorizer.tfidf_vectorizer import build_TfIdfModel_from_list_of_texts, save_tfidf_model, convert_text_to_tfidf\n",
    "from nlp.vectorizer.lsi_vectorizer import save_lsi_model, convert_text_to_lsi, build_LsiTopicModel\n",
    "\n",
    "def load_document(filename):\n",
    "    s = []\n",
    "    flist = glob.glob(filename)\n",
    "    for fname in flist:\n",
    "    #print(fname)\n",
    "        tfile = open(fname, \"r\", encoding=\"utf-8\", errors='ignore')\n",
    "        line = tfile.read()  # read the content of file and store in \"line\"\n",
    "        tfile.close()  # close the file\n",
    "        s.append(line)\n",
    "\n",
    "    return s\n",
    "\n",
    "def get_dictionary(documents, output) :\n",
    "    my_dict = build_dictionary(documents)\n",
    "    save(my_dict, output)\n",
    "    return my_dict\n",
    "\n",
    "def get_tfidf_model(documents, dictionary, output) :\n",
    "    tfidf_model = build_TfIdfModel_from_list_of_texts(documents, dictionary)\n",
    "    save_tfidf_model(tfidf_model, output)\n",
    "    return tfidf_model\n",
    "\n",
    "def get_lsi_model(documents, dictionary_filename, tfidf_output, numtopics, output) :\n",
    "    lsi_model = build_LsiTopicModel(documents, dictionary_filename, tfidf_output, numtopics)\n",
    "    save_lsi_model(output, lsi_model)\n",
    "    return lsi_model\n",
    "\n",
    "def sort_keywords(tfidf, reverse=True) :\n",
    "    #sorted by Idf value of each word\n",
    "    #idf value would return tuple (0,0.123231) => 1st element is the key in the dictionary, 2nd element is the idf value\n",
    "    #higher of idf value means higher word frequency\n",
    "    return sorted(tfidf, key=lambda item : item[1], reverse=reverse)\n",
    "\n",
    "def get_keywords(tfidf, dictionary) :\n",
    "    sorted_keywords = sort_keywords(tfidf)\n",
    "    keywords = map(lambda item: dictionary.get(item[0]), sorted_keywords)\n",
    "    #you have to convert it back to list if you want to return the values\n",
    "    return list(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-23 21:45:56,974 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-08-23 21:45:58,644 : INFO : built Dictionary(48736 unique tokens: ['ada', 'adalah', 'adanya', 'ade', 'agar']...) from 2969 documents (total 1428944 corpus positions)\n",
      "2018-08-23 21:45:58,669 : INFO : saving Dictionary object under dictionary/artikel_result.dict, separately None\n",
      "2018-08-23 21:45:58,688 : INFO : saved dictionary/artikel_result.dict\n",
      "2018-08-23 21:46:08,967 : INFO : collecting document frequencies\n",
      "2018-08-23 21:46:08,970 : INFO : PROGRESS: processing document #0\n",
      "2018-08-23 21:46:09,208 : INFO : calculating IDF weights for 2969 documents and 48735 features (693048 matrix non-zeros)\n",
      "2018-08-23 21:46:09,344 : INFO : saving TfidfModel object under tf_idf/artikel_result.tfidf, separately None\n",
      "2018-08-23 21:46:09,529 : INFO : saved tf_idf/artikel_result.tfidf\n",
      "2018-08-23 21:46:09,530 : INFO : loading Dictionary object from dictionary/artikel_result.dict\n",
      "2018-08-23 21:46:09,555 : INFO : loaded dictionary/artikel_result.dict\n",
      "2018-08-23 21:46:09,556 : INFO : loading TfidfModel object from tf_idf/artikel_result.tfidf\n",
      "2018-08-23 21:46:09,622 : INFO : loaded tf_idf/artikel_result.tfidf\n",
      "2018-08-23 21:46:24,412 : INFO : using serial LSI version on this node\n",
      "2018-08-23 21:46:24,413 : INFO : updating model with new documents\n",
      "2018-08-23 21:46:24,414 : INFO : preparing a new chunk of documents\n",
      "2018-08-23 21:46:24,568 : INFO : using 100 extra samples and 2 power iterations\n",
      "2018-08-23 21:46:24,570 : INFO : 1st phase: constructing (48736, 200) action matrix\n",
      "2018-08-23 21:46:24,745 : INFO : orthonormalizing (48736, 200) action matrix\n",
      "2018-08-23 21:46:30,249 : INFO : 2nd phase: running dense svd on (200, 2969) matrix\n",
      "2018-08-23 21:46:30,565 : INFO : computing the final decomposition\n",
      "2018-08-23 21:46:30,566 : INFO : keeping 100 factors (discarding 25.723% of energy spectrum)\n",
      "2018-08-23 21:46:30,712 : INFO : processed documents up to #2969\n",
      "2018-08-23 21:46:30,722 : INFO : topic #0(8.652): 0.186*\"anak\" + 0.158*\"anda\" + 0.108*\"jantung\" + 0.108*\"kanker\" + 0.102*\"darah\" + 0.100*\"bayi\" + 0.094*\"makanan\" + 0.093*\"ibu\" + 0.086*\"penyakit\" + 0.085*\"diabetes\"\n",
      "2018-08-23 21:46:30,725 : INFO : topic #1(4.426): -0.412*\"asi\" + -0.367*\"bayi\" + -0.273*\"anak\" + -0.263*\"ibu\" + 0.175*\"diabetes\" + 0.169*\"jantung\" + -0.131*\"menyusui\" + 0.128*\"gula\" + -0.117*\"formula\" + 0.117*\"darah\"\n",
      "2018-08-23 21:46:30,728 : INFO : topic #2(4.328): -0.371*\"kanker\" + 0.233*\"asi\" + -0.192*\"hepatitis\" + -0.184*\"hpv\" + 0.171*\"makanan\" + -0.165*\"serviks\" + 0.152*\"bayi\" + -0.139*\"vaksin\" + -0.135*\"virus\" + -0.130*\"hiv\"\n",
      "2018-08-23 21:46:30,731 : INFO : topic #3(4.136): -0.488*\"anak\" + 0.241*\"asi\" + 0.190*\"kanker\" + -0.172*\"tidur\" + 0.170*\"bayi\" + 0.137*\"ibu\" + 0.136*\"payudara\" + 0.133*\"vitamin\" + 0.117*\"kehamilan\" + 0.114*\"kulit\"\n",
      "2018-08-23 21:46:30,733 : INFO : topic #4(3.909): -0.532*\"kanker\" + -0.254*\"anak\" + 0.161*\"hepatitis\" + -0.151*\"serviks\" + -0.140*\"payudara\" + -0.127*\"hpv\" + 0.119*\"hiv\" + -0.106*\"makanan\" + 0.104*\"darah\" + 0.099*\"obat\"\n",
      "2018-08-23 21:46:30,760 : INFO : saving Projection object under lsi/artikel_result.lsi.projection, separately None\n",
      "2018-08-23 21:46:32,062 : INFO : saved lsi/artikel_result.lsi.projection\n",
      "2018-08-23 21:46:32,064 : INFO : saving LsiModel object under lsi/artikel_result.lsi, separately None\n",
      "2018-08-23 21:46:32,065 : INFO : not storing attribute projection\n",
      "2018-08-23 21:46:32,066 : INFO : not storing attribute dispatcher\n",
      "2018-08-23 21:46:32,130 : INFO : saved lsi/artikel_result.lsi\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filename = r'artikel/*.txt'\n",
    "    output_filedict = 'dictionary/artikel_result.dict'\n",
    "    output_tfidf = 'tf_idf/artikel_result.tfidf'\n",
    "    output_lsi = \"lsi/artikel_result.lsi\"\n",
    "    \n",
    "    documents = load_document(filename)\n",
    "    dictionary = get_dictionary(documents, output_filedict)\n",
    "\n",
    "    #get our tfidf_model\n",
    "    tfidf_model = get_tfidf_model(documents, dictionary, output_tfidf)\n",
    "    \n",
    "    #get lsi model\n",
    "    lsi_model = get_lsi_model(documents, output_filedict, output_tfidf, 100, output_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.07818671203016449), (1, 0.00041254028681540083), (2, -0.002357423059857172), (3, -0.04735748089889817), (4, 0.016830233701086737), (5, -0.018997273036704638), (6, 0.0015581881709658422), (7, -0.012985546338644845), (8, 0.010969893027024209), (9, -0.0178045441708118), (10, 0.025173120139281215), (11, 0.019563807989688008), (12, -0.02508368940075561), (13, -0.022026737930019517), (14, 0.019188343325035547), (15, 0.010284402242063862), (16, -0.005288161405238253), (17, -0.00402358038698052), (18, 0.03616708745191964), (19, -0.04124750845251615), (20, 0.03587983225970891), (21, -0.060600678974893386), (22, -0.06728160691257531), (23, 0.08489568155777426), (24, -0.03367936092877198), (25, -0.07789046680381827), (26, 0.006564937493007829), (27, 0.016122606039506996), (28, 0.008470251563250574), (29, -0.03593025150395827), (30, -0.001024966290132078), (31, -0.054765511010879425), (32, 0.00154840210262587), (33, 0.01040632260470082), (34, -0.008505622115913603), (35, 0.0007241135135359068), (36, 0.01295647715303785), (37, 0.0038405695929956997), (38, -0.03148104825078466), (39, -0.04101516595766788), (40, 0.043501112582497156), (41, -0.005226825869688504), (42, -0.000469868529245991), (43, -0.01989884186656076), (44, -0.012151784986513849), (45, -0.01277962161953815), (46, -0.028810962631615724), (47, 0.03166487061138694), (48, 0.025955429906764273), (49, 0.04004577015482465), (50, -0.011284821192907937), (51, -4.418053750041115e-05), (52, -0.002280875552078487), (53, 0.02452204697545676), (54, 0.030647659077870114), (55, 0.02035050235932992), (56, -0.0472875359249221), (57, -0.008151004310208303), (58, -0.007717218176872861), (59, -9.983928147437364e-05), (60, -0.05197927516907977), (61, -0.021593174080926373), (62, -0.032701432289468174), (63, 0.028345502965371996), (64, 0.027008513809289404), (65, -0.00043503251631381464), (66, -0.027528577653845768), (67, -0.01122679948744665), (68, -0.011622766681213254), (69, -0.02130486280837528), (70, -0.017327170326391323), (71, -0.022121600450271683), (72, 0.012674271828039234), (73, 0.0009879838251864548), (74, -0.0017331843161097317), (75, 0.01822619505520548), (76, -0.0017745353456136918), (77, -0.01598831798517839), (78, 0.032820179366889836), (79, -0.0007901711832972728), (80, -0.001516608977876676), (81, -0.005841344373820458), (82, -0.012645787093238487), (83, 0.038566156346701054), (84, 0.01664405921475352), (85, -0.0021054150968188366), (86, 0.015859236314709257), (87, -0.0027040705339336038), (88, -0.02796365155751506), (89, 0.051026272908630384), (90, 0.0133770158026085), (91, -0.017131762145968468), (92, -0.009280820318524249), (93, 0.007623672547889498), (94, -0.017685311849494487), (95, 0.01502863930469121), (96, -0.005049815465073484), (97, -0.010080265594781378), (98, -0.013833817188049444), (99, -0.0015528759585383544)]\n",
      "[('anak', 0.18625293702398352), ('anda', 0.15848160857236782), ('jantung', 0.10821324211907328), ('kanker', 0.10762295294509718), ('darah', 0.10172926020238088), ('bayi', 0.09959402270103501), ('makanan', 0.09392445311949388), ('ibu', 0.09312558797442733), ('penyakit', 0.08595530579575913), ('diabetes', 0.08502843242043512)]\n"
     ]
    }
   ],
   "source": [
    "    #example of LSI dari document 3\n",
    "    sample = documents[3]\n",
    "    lsi  = convert_text_to_lsi(sample, dictionary, tfidf_model, lsi_model)\n",
    "    print(lsi)\n",
    "    \n",
    "    # find topic\n",
    "    print(lsi_model.show_topic(0,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
